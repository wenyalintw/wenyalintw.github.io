<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Wen-Ya Lin</title>
    <link>https://wenyalintw.github.io/project/</link>
    <description>Recent content in Projects on Wen-Ya Lin</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&amp;copy;{year} Wen-Ya Lin</copyright>
    <lastBuildDate>Sun, 27 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://wenyalintw.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Dicom-Viewer</title>
      <link>https://wenyalintw.github.io/project/dicom-viewer/</link>
      <pubDate>Sun, 27 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://wenyalintw.github.io/project/dicom-viewer/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;
  &lt;h2 align=&#34;center&#34;&gt;簡易醫學影像GUI (Dicom Viewer)&lt;/h2&gt;
  &lt;p align=&#34;center&#34;&gt;能顯示 2D/3D Dicom影像的應用&lt;/p&gt;
  &lt;br&gt;
&lt;/p&gt;

&lt;p&gt;本project旨在利用python+Qt製作簡易的醫學影像GUI，提供一個平台，能在上面使用python開發測試各式影像處理功能，尤其是針對3D之Dicom Stack！&lt;/p&gt;

&lt;h2 id=&#34;demo&#34;&gt;先看兩段Demo吧&lt;/h2&gt;

&lt;h3 id=&#34;ahrefhttpswwwyoutubecomwatchvtoxcznnnz4cfeatureyoutube2dimageprocessinga&#34;&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=TOXczNnnZ4c&amp;amp;feature=youtu.be&#34;&gt;2D Image Processing&lt;/a&gt;&lt;/h3&gt;

&lt;p align=&#34;center&#34;&gt;
&lt;iframe width=&#34;640&#34; height=&#34;360&#34; src=&#34;https://www.youtube.com/embed/TOXczNnnZ4c&#34;&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;h3 id=&#34;ahrefhttpswwwyoutubecomwatchvns75aqovossfeatureyoutube3dimageprocessinga&#34;&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=NS75AQOVOss&amp;amp;feature=youtu.be&#34;&gt;3D Image Processing&lt;/a&gt;&lt;/h3&gt;

&lt;p align=&#34;center&#34;&gt;
&lt;iframe width=&#34;640&#34; height=&#34;360&#34; src=&#34;https://www.youtube.com/embed/NS75AQOVOss&#34;&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;h2 id=&#34;&#34;&gt;執行畫面&lt;/h2&gt;

&lt;p&gt;執行程式會打開Main Window，左上角的選單有2D processing和3D processing兩個子選項，其中後者embed有3D volume reconstruction功能&lt;/p&gt;

&lt;h3 id=&#34;mainwindow&#34;&gt;Main Window&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/wenyalintw/Dicom_Viewer&#34;&gt;
    &lt;img src=&#34;resources/mainwindow.png&#34; alt=&#34;mainwindow&#34; width=&#34;960&#34; height=&#34;480&#34;&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;2dprocessing&#34;&gt;2D processing&lt;/h3&gt;

&lt;p&gt;內含功能&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Load Image (含*.dcm)&lt;/li&gt;

&lt;li&gt;Save Image&lt;/li&gt;

&lt;li&gt;Convert to gray scale&lt;/li&gt;

&lt;li&gt;Restore&lt;/li&gt;

&lt;li&gt;Thresholding&lt;/li&gt;

&lt;li&gt;Region Growing&lt;/li&gt;

&lt;li&gt;Morthology (Dilation, Erosion, Opening, Closing)&lt;/li&gt;

&lt;li&gt;Edge Detection (Laplacian, Sobel, Perwitt, Frei &amp;amp; Chen)&lt;/li&gt;

&lt;li&gt;Drawing
&lt;br&gt;
&lt;a href=&#34;https://github.com/wenyalintw/Dicom_Viewer&#34;&gt;
&lt;img src=&#34;resources/2D_Processing.jpg&#34; alt=&#34;2D_Processing&#34; width=&#34;960&#34; height=&#34;480&#34;&gt;
&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;3dprocessing&#34;&gt;3D processing&lt;/h3&gt;

&lt;p&gt;內含功能&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Load DICOM stack&lt;/li&gt;

&lt;li&gt;Save slice (axial, sagittal, coronal)&lt;/li&gt;

&lt;li&gt;Colormap transform&lt;/li&gt;

&lt;li&gt;Slider scrolling&lt;/li&gt;

&lt;li&gt;Mouse hovering/clicking&lt;/li&gt;

&lt;li&gt;Show DICOM info&lt;/li&gt;

&lt;li&gt;Show slice index coordinate&lt;/li&gt;

&lt;li&gt;3D volume reconstruction
&lt;br&gt;
&lt;a href=&#34;https://github.com/wenyalintw/Dicom_Viewer&#34;&gt;
&lt;img src=&#34;resources/3D_Processing.jpg&#34; alt=&#34;3D_Processing&#34; width=&#34;960&#34; height=&#34;480&#34;&gt;
&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;3dvolumereconstruction&#34;&gt;3D volume reconstruction&lt;/h3&gt;

&lt;p&gt;&lt;br&gt;
&lt;a href=&#34;https://github.com/wenyalintw/Dicom_Viewer&#34;&gt;
    &lt;img src=&#34;resources/3D_Volume.jpg&#34; alt=&#34;3D_Volume&#34; width=&#34;480&#34; height=&#34;480&#34;&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;futureextension&#34;&gt;Future Extension&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;加入數據分析功能
&gt;導入一些醫學知識，讓軟體有一些初步的分析功能（如有沒有骨折、腫瘤等等）&lt;/li&gt;

&lt;li&gt;3D reconstruction改善
&gt;更新volume重建算法，提升計算速度與還原度&lt;/li&gt;

&lt;li&gt;3D image processing
&gt;加入對3D voxel影像進行更複雜的影像處理功能&lt;/li&gt;

&lt;li&gt;Make it distributable
&gt;包裝成release版本，成為可轉散發軟體。希望能支援跨平台運作（window、macOS）&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;howtouseit&#34;&gt;How to use it?&lt;/h2&gt;

&lt;p&gt;Project root will be &lt;strong&gt;/src&lt;/strong&gt;, just clone it and run mainwindow.py.&lt;/p&gt;

&lt;p&gt;Strictly follow the package version in requirements.txt is not necessary.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Spoken-Digit Recognizer</title>
      <link>https://wenyalintw.github.io/project/spoken-digit-recognizer/</link>
      <pubDate>Sun, 27 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://wenyalintw.github.io/project/spoken-digit-recognizer/</guid>
      <description>&lt;p align=&#34;center&#34;&gt;
  &lt;h2 align=&#34;center&#34;&gt;語音數字辨識專案 (Spoken-Digit Recognizer)&lt;/h2&gt;
  &lt;div align=&#34;center&#34;&gt;
    本project旨在運用Keras建立Model，辨識使用者說的中/英數字，並使用GUI呈現。
  &lt;/div&gt;
&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/tree/master/src/split_audio&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Split--Audio-src-brightgreen.svg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://github.com/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/tree/master/src/Spectrogram_CNN&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Spectrogram%2BCNN-src-brightgreen.svg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://github.com/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/tree/master/src/MFCC_RNN&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/MFCC%2BRNN-src-brightgreen.svg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://github.com/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/tree/master/src/Gan&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GAN-src-brightgreen.svg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://github.com/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/tree/master/src/Demo&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Demo-src-brightgreen.svg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/docs/split_audio.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Split--Audio-doc-blue.svg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/docs/Spectrogram_CNN_doc.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Spectrogram%2BCNN-doc-blue.svg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/docs/MFCC_RNN_doc.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/MFCC%2BRNN-doc-blue.svg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/docs/GAN_doc.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/GAN-doc-blue.svg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/docs/Demo_doc.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Demo-doc-blue.svg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;demo&#34;&gt;先看段Demo吧！&lt;/h2&gt;

&lt;h3 id=&#34;spokendigitrecognizerdemoyoutubehttpswwwyoutubecomwatchv_ykum1dxpjm&#34;&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=_yKum1DxPJM&#34;&gt;Spoken-Digit Recognizer – Demo (YouTube)&lt;/a&gt;&lt;/h3&gt;
&lt;p align=&#34;center&#34;&gt;
&lt;iframe width=&#34;640&#34; height=&#34;360&#34; src=&#34;https://www.youtube.com/embed/_yKum1DxPJM&#34;&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;p&gt;Demo詳細介紹請點連結&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;### &lt;a href=&#34;https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/docs/Demo_doc.ipynb&#34;&gt;(Detailed) Demo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;所有使用data皆置於&lt;a href=&#34;https://github.com/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/dataset.rar&#34;&gt;dataset.rar&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;&#34;&gt;英文&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pannous/tensorflow-speech-recognition?fbclid=IwAR1tThhKhbMM_BnKE4SK16qcbuGdw1gJw7iWVVyEhDk9vZFF5Z8E6rjuWUs&#34;&gt;pannous on github&lt;/a&gt;


&lt;ul&gt;
&lt;li&gt;連結內spoken&lt;em&gt;numbers&lt;/em&gt;pcm.tar含2400筆.wav檔，為15位不同人唸英文數字(0~9)的單數字音檔(160/人)&lt;/li&gt;&lt;/ul&gt;
&lt;/li&gt;

&lt;li&gt;3位contributer每人自錄160筆，與上述相加共2880筆&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;-1&#34;&gt;中文&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;3位contributer每人自錄500筆，共1500筆


&lt;ul&gt;
&lt;li&gt;每筆data為中文數字數字0~9單數字音檔，每人一個數字錄50筆&lt;/li&gt;&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;-2&#34;&gt;目標&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;使用者對麥克風説一串中/英文數字(0~9)，程式能辨識使用者說了哪些數字  &lt;/li&gt;

&lt;li&gt;使用生成對抗網路GAN來生成音檔，即讓程式產出數字0~9的音檔&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;implementation&#34;&gt;Implementation&lt;/h2&gt;

&lt;p&gt;對目標1，先將包含多數字的音檔分割，再使用不同種model來辨識，詳細介紹請點連結&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;### &lt;a href=&#34;https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/docs/split_audio.ipynb&#34;&gt;(Detailed) Split Audio&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;### &lt;a href=&#34;https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/docs/Spectrogram_CNN_doc.ipynb&#34;&gt;(Detailed) Spectrogram + CNN&lt;/a&gt;    &lt;/li&gt;

&lt;li&gt;### &lt;a href=&#34;https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/docs/MFCC_RNN_doc.ipynb&#34;&gt;(Detailed) MFCC + RNN&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;對目標2，使用inverse-STFT方式，詳細介紹請點連結&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;### &lt;a href=&#34;https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/docs/GAN_doc.ipynb&#34;&gt;(Detailed) GAN&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;-3&#34;&gt;問題討論&lt;/h2&gt;

&lt;h3 id=&#34;1&#34;&gt;1. 聲紋影響&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;- 一個沒有經過我們model訓練過的人聲，若進行辨識測驗時的平均正確率會較低
- 我們認為這和聲紋息息相關，也就是同樣的字由不同人發聲的訊號頻譜存在差異
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2&#34;&gt;2. 中/英文&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;- 我們初期是以英文數字為輸入音訊，後期則發現英文其實在發音上相較中文有更多的變化性，如某些子音的發音屬於清音，會較容易被誤判為靜音
- 英文對於發音並沒有制式的音調規則，例如有些字會因語氣不同而音調不同，這導致我們model的辨識正確率並不理想
- 後來我們選擇嘗試中文，由於中文絕大多數發音是濁音，且抑揚頓挫已有明確定義，因此訓練出的model辨識正確率果然如我們預期，有明顯的提升
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;contributors&#34;&gt;Contributors&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/wenyalintw&#34;&gt;WenYa Lin&lt;/a&gt;、&lt;a href=&#34;https://github.com/ChungYuanHsu&#34;&gt;ChungYuan Hsu&lt;/a&gt;、&lt;a href=&#34;https://github.com/r07522749&#34;&gt;JauhHsiang Lan&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
